{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the blueprint library and filter for the vehicle blueprints\n",
    "vehicle_bp = world.get_blueprint_library().filter('*vehicle*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the blueprints, we need to find some appropriate spots in the map to spawn our vehicles. Each CARLA map provides pre-defined spawn points spread evenly throughout the map on the roads for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "# Spawn 50 vehicles randomly distributed throughout the map \n",
    "# for each spawn point, we choose a random vehicle from the blueprint library\n",
    "# These vehicles will not move\n",
    "for i in range(0,10):\n",
    "    world.try_spawn_actor(random.choice(vehicle_bp), random.choice(spawn_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should also add a vehicle that will be the centerpoint of our simulation. To train an autonomous agent we need to simulate a the vehicle that it the autonomous agent will control. In CARLA parlance, we often refer to this vehicle as the \"Ego vehicle\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_vehicle = world.spawn_actor(random.choice(vehicle_bp), random.choice(spawn_points)) # Everytime this runs, a new vehicle is created\n",
    "spectator = world.get_spectator()\n",
    "spectator.set_transform(ego_vehicle.get_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sensors\n",
    "\n",
    "Modern autonomous vehicles understand and interpret their environment through an array of attached sensors. These sensors include things such as optical video cameras, optical flow cameras, LIDARs, RADARs and accelerometers. CARLA has models of numerous types of sensors built in to create training data for machine learning. The sensors can be attached to a vehicle, or they can be attached to a fixed point to model for example a CCTV camera.\n",
    "\n",
    "Here we will attach a standard camera sensor to the ego vehicle to record some video data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform to place the camera on top of the vehicle\n",
    "camera_init_trans = carla.Transform(carla.Location(z=1.5))\n",
    "\n",
    "# We create the camera through a blueprint that defines its properties\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "\n",
    "# We spawn the camera and attach it to our ego vehicle\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=ego_vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have spawned the camera, we need to set it recording through the listen() method. The listen method takes as argument a callback that defines what to do with the data. You can either stream it to another program or save it to disk.\n",
    "\n",
    "We will use a lambda function as a callback to save the data to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start camera with PyGame callback\n",
    "camera.listen(lambda image: image.save_to_disk('out/%06d.png' % image.frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop() # Stop the camera\n",
    "# camera.destroy() # Destroy the camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will save the data to the out/ folder as a series of PNG image files named according to the simulation frame number.\n",
    "\n",
    "There are a multitude of different types of sensors to choose from. [Here](https://carla.readthedocs.io/en/latest/core_sensors/) you can delve deeper into the array of sensors available and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensors step-by-step\n",
    "\n",
    "The class carla.Sensor defines a special type of actor able to measure and stream data.\n",
    "\n",
    "- What is this data? It varies a lot depending on the type of sensor. All the types of data are inherited from the general carla.SensorData.\n",
    "- When do they retrieve the data? Either on every simulation step or when a certain event is registered. Depends on the type of sensor.\n",
    "- How do they retrieve the data? Every sensor has a listen() method to receive and manage the data.\n",
    "\n",
    "Despite their differences, all the sensors are used in a similar way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "carla.SensorData\n",
    "\n",
    "Base class for all the objects containing data generated by a carla.Sensor. This objects should be the argument of the function said sensor is listening to, in order to work with them. Each of these sensors needs for a specific type of sensor data. Hereunder is a list of the sensors and their corresponding data.\n",
    "- Cameras (RGB, depth and semantic segmentation): carla.Image.\n",
    "- Collision detector: carla.CollisionEvent.\n",
    "- GNSS sensor: carla.GnssMeasurement.\n",
    "- IMU sensor: carla.IMUMeasurement.\n",
    "- Lane invasion detector: carla.LaneInvasionEvent.\n",
    "- LIDAR sensor: carla.LidarMeasurement.\n",
    "- Obstacle detector: carla.ObstacleDetectionEvent.\n",
    "- Radar sensor: carla.RadarMeasurement.\n",
    "- RSS sensor: carla.RssResponse.\n",
    "- Semantic LIDAR sensor: carla.SemanticLidarMeasurement.\n",
    "- Cooperative awareness messages V2X sensor: carla.CAMEvent.\n",
    "- Custom V2X messages V2X sensor: carla.CustomV2XEvent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n",
    "\n",
    "As with every other actor, find the blueprint and set specific attributes. This is essential when handling sensors. Their attributes will determine the results obtained. These are detailed in the sensors reference.\n",
    "\n",
    "The following example sets a dashboard HD camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the blueprint of the sensor.\n",
    "blueprint = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "# Modify the attributes of the blueprint to set image resolution and field of view.\n",
    "blueprint.set_attribute('image_size_x', '1920')\n",
    "blueprint.set_attribute('image_size_y', '1080')\n",
    "blueprint.set_attribute('fov', '110')\n",
    "# Set the time in seconds between sensor captures\n",
    "blueprint.set_attribute('sensor_tick', '1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawning\n",
    "\n",
    "attachment_to and attachment_type, are crucial. Sensors should be attached to a parent actor, usually a vehicle, to follow it around and gather the information. The attachment type will determine how its position is updated regarding said vehicle.\n",
    "\n",
    "- Rigid attachment. Movement is strict regarding its parent location. This is the proper attachment to retrieve data from the simulation.\n",
    "- SpringArm attachment. Movement is eased with little accelerations and decelerations. This attachment is only recommended to record videos from the simulation. The movement is smooth and \"hops\" are avoided when updating the cameras' positions.\n",
    "- SpringArmGhost attachment. Like the previous one but without doing the collision test, so the camera or sensor could cross walls or other geometries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When spawning with attachment, location must be relative to the parent actor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "transform = carla.Transform(carla.Location(x=0.8, z=1.7))\n",
    "sensor = world.spawn_actor(blueprint, transform, attach_to=ego_vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listening \n",
    "\n",
    "Every sensor has a listen() method. This is called every time the sensor retrieves data.\n",
    "\n",
    "The argument callback is a lambda function. It describes what should the sensor do when data is retrieved. This must have the data retrieved as an argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animate vehicles with traffic manager\n",
    "\n",
    "Now we've added our traffic and ego vehicle to the simulation and started recording camera data, we now need to set the vehicles in motion using the Traffic manager. The Traffic manager is a component of CARLA that controls vehicles to autonomously move around the roads of the map within the simulation, following the road conventions and behaving like real road users.\n",
    "\n",
    "We can find all the vehicles in the simulation using the world.get_actors() method, filtering for all the vehicles. We can then use the set_autopilot() method to hand over control of the vehicle to the Traffic Manager.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vehicle in world.get_actors().filter('vehicle.*'):\n",
    "    vehicle.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your simulation is running, with numerous vehicles driving around the map and a camera recording data from one of those vehicles. This data can then be used to feed a machine learning algorithm for training an autonomous driving agent. The Traffic manager has many functions for customising traffic behaviour, learn more [here](https://carla.readthedocs.io/en/latest/tuto_G_traffic_manager/).\n",
    "\n",
    "This is the most basic possible set up for a simulation, now you can go into further details deeper into documentation about the many extra sensors you can use to generate data, and the many other features of CARLA that can make your simulations more detailed and more realistic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign a vehicle as the Ego Vehicle\n",
    "\n",
    "The Ego Vehicle is an important concept to bear in mind when using CARLA. The Ego Vehicle refers to the vehicle that will be the focus of the simulation. In most CARLA use cases it's likely to be the vehicle to which you will attach your sensors and/or the vehicle that your autonomous driving machine learning stack will control. It is important because it serves as the basis for some simulation operations that help improve the efficiency of the simulation, like for example:\n",
    "\n",
    "- Loading map tiles for Large Maps: Large Maps (like Town 12) are made up of tiles to that are only loaded when needed to improve CARLA performance. The position of the Ego Vehicle dictates which tiles are used. Only the tiles nearest the Ego Vehicle will be loaded.\n",
    "\n",
    "- Hybrid Physics Mode: if your simulation contains a lot of vehicles controlled by the Traffic Manager, calculating physics for all of these vehicles is very computationally expensive. The Hybrid Physics Mode enables physics calculation to be limited to the vehicles in the vicinity of the Ego Vehicle, hence saving computing resources.\n",
    "\n",
    "To define the Ego Vehicle, you should set the role_name attribute of the vehicle carla.Actor object's blueprint when you are spawning your Ego Vehicle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_bp = world.get_blueprint_library().find('vehicle.lincoln.mkz_2020')\n",
    "ego_bp.set_attribute('role_name', 'hero')\n",
    "ego_vehicle = world.spawn_actor(ego_bp, random.choice(spawn_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectator.set_transform(ego_vehicle.get_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARLA comes loaded with several pre-made maps focused on providing a diversity of features. The maps present a range of environments such as urban, rural and residential. There are also differing architectural styles and also a multitude of different road layouts from unmarked rural roads to multi-lane highways. Browse the map guides in the [catalogue](https://carla.readthedocs.io/en/latest/catalogue/) or in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Game/Carla/Maps/Town04',\n",
       " '/Game/Carla/Maps/Town01',\n",
       " '/Game/Carla/Maps/Town02',\n",
       " '/Game/Carla/Maps/Town01_Opt',\n",
       " '/Game/Carla/Maps/Town03_Opt',\n",
       " '/Game/Carla/Maps/Town10HD_Opt',\n",
       " '/Game/Carla/Maps/Town07',\n",
       " '/Game/Carla/Maps/Town05',\n",
       " '/Game/Carla/Maps/Town02_Opt',\n",
       " '/Game/Carla/Maps/Town10HD',\n",
       " '/Game/Carla/Maps/Town04_Opt',\n",
       " '/Game/Carla/Maps/Town05_Opt',\n",
       " '/Game/Carla/Maps/Town03',\n",
       " '/Game/Carla/Maps/Town06',\n",
       " '/Game/Carla/Maps/Town11/Town11',\n",
       " '/Game/Carla/Maps/Town13/Town13',\n",
       " '/Game/Carla/Maps/Town15/Town15',\n",
       " '/Game/Carla/Maps/Town12/Town12']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_available_maps() # Avaliable maps\n",
    "client.load_world('Town01') # Load a new map, TENDS TO CRASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle.audi.a2\n",
      "vehicle.citroen.c3\n",
      "vehicle.chevrolet.impala\n",
      "vehicle.dodge.charger_police_2020\n",
      "vehicle.micro.microlino\n",
      "vehicle.dodge.charger_police\n",
      "vehicle.audi.tt\n",
      "vehicle.jeep.wrangler_rubicon\n",
      "vehicle.mercedes.coupe\n",
      "vehicle.yamaha.yzf\n",
      "vehicle.mercedes.coupe_2020\n",
      "vehicle.harley-davidson.low_rider\n",
      "vehicle.dodge.charger_2020\n",
      "vehicle.ford.ambulance\n",
      "vehicle.lincoln.mkz_2020\n",
      "vehicle.mini.cooper_s_2021\n",
      "vehicle.ford.crown\n",
      "vehicle.toyota.prius\n",
      "vehicle.carlamotors.european_hgv\n",
      "vehicle.carlamotors.carlacola\n",
      "vehicle.vespa.zx125\n",
      "vehicle.nissan.patrol_2021\n",
      "vehicle.mercedes.sprinter\n",
      "vehicle.audi.etron\n",
      "vehicle.seat.leon\n",
      "vehicle.volkswagen.t2_2021\n",
      "vehicle.tesla.cybertruck\n",
      "vehicle.lincoln.mkz_2017\n",
      "vehicle.carlamotors.firetruck\n",
      "vehicle.ford.mustang\n",
      "vehicle.volkswagen.t2\n",
      "vehicle.mitsubishi.fusorosa\n",
      "vehicle.tesla.model3\n",
      "vehicle.diamondback.century\n",
      "vehicle.gazelle.omafiets\n",
      "vehicle.bmw.grandtourer\n",
      "vehicle.bh.crossbike\n",
      "vehicle.kawasaki.ninja\n",
      "vehicle.nissan.patrol\n",
      "vehicle.nissan.micra\n",
      "vehicle.mini.cooper_s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for bp in world.get_blueprint_library().filter('vehicle'):\n",
    "    print(bp.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
